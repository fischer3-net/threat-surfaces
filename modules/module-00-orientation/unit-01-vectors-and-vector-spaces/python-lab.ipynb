{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "course": {
   "name": "Threat Surfaces: Multivariable Calculus for AI Security",
   "organization": "fischer\u00b3 Education",
   "module": "Module 00, Unit 01",
   "title": "Vectors & Vector Spaces",
   "type": "python-lab"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Python Lab — Module 00, Unit 01: Vectors & Vector Spaces\n",
    "\n",
    "> **Threat Surfaces: Multivariable Calculus for AI Security**  \n",
    "> fischer³ Education | Module 00 | Unit 01\n",
    ">\n",
    "> **Estimated time**: 15–20 minutes  \n",
    "> **Prerequisite**: Complete `notes.md` and attempt `exercises.tex` before running this lab\n",
    "\n",
    "---\n",
    "\n",
    "## What This Lab Does\n",
    "\n",
    "The exercises built algebraic fluency with vectors. This lab adds two things the exercises cannot: **geometric visualization** and **symbolic verification**. By the end you will have seen vectors as arrows in space, watched scalar multiplication stretch and reverse them, and plotted the first parameter-space visualization of the course — a preview of what optimization landscapes look like.\n",
    "\n",
    "## Lab Objectives\n",
    "\n",
    "- [ ] Verify Exercise 1 computations using NumPy and SymPy\n",
    "- [ ] Visualize vector addition (parallelogram rule) in $\\mathbb{R}^2$\n",
    "- [ ] Visualize scalar multiplication and normalization in $\\mathbb{R}^2$\n",
    "- [ ] Plot the three unit balls ($\\ell_1$, $\\ell_2$, $\\ell_\\infty$) from Exercise 4\n",
    "- [ ] Build a first parameter-space visualization: the Ridge regression penalty surface\n",
    "\n",
    "## Connection to Exercises\n",
    "\n",
    "Section 1 verifies Problems 1 and 2 symbolically. Section 2 visualizes the geometry from Problem 1. Section 3 visualizes the unit ball geometry from Problem 4. Section 4 (statistical bridge) extends Problem 3 into a surface plot of the Ridge penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Imports\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import sympy as sp\n",
    "from sympy import sqrt, Rational, simplify, latex\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams.update({\n",
    "    'figure.figsize': (9, 6),\n",
    "    'font.size': 11,\n",
    "    'axes.titlesize': 13,\n",
    "    'axes.labelsize': 11,\n",
    "    'lines.linewidth': 2,\n",
    "    'figure.dpi': 120\n",
    "})\n",
    "\n",
    "# Course color palette\n",
    "TS_BLUE   = '#1e64b4'\n",
    "TS_AMBER  = '#c87814'\n",
    "TS_GREEN  = '#1e8c50'\n",
    "TS_GRAY   = '#64646e'\n",
    "TS_RED    = '#b41e1e'\n",
    "TS_LIGHT  = '#f5f7fa'\n",
    "\n",
    "print('Imports complete. Python lab ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sec1-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 1 — Symbolic Verification\n",
    "\n",
    "We verify the computations from Exercises 1 and 2 using SymPy. The goal is to confirm your hand solutions are correct **and** to establish the habit of treating SymPy as a reliable check — not a shortcut to skip hand work.\n",
    "\n",
    "If your hand solution disagrees with SymPy, trust SymPy and find the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex1-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define vectors from Exercise 1 as SymPy matrices (exact arithmetic) ---\n",
    "a = sp.Matrix([2, -3, 1])\n",
    "b = sp.Matrix([-1, 4, 2])\n",
    "\n",
    "print('a =', a.T)  # .T prints as row for readability\n",
    "print('b =', b.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex1-arithmetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Exercise 1(a): Vector arithmetic ---\n",
    "sum_ab    = a + b\n",
    "diff_3a2b = 3*a - 2*b\n",
    "half_mix  = sp.Rational(1,2)*a + sp.Rational(3,2)*b\n",
    "\n",
    "print('a + b         =', sum_ab.T)\n",
    "print('3a - 2b       =', diff_3a2b.T)\n",
    "print('(1/2)a+(3/2)b =', half_mix.T)\n",
    "\n",
    "print('\\n--- Enter your hand answers below to verify ---')\n",
    "# Replace None with your hand-computed SymPy matrices to check\n",
    "my_sum    = None  # e.g. sp.Matrix([1, 1, 3])\n",
    "my_diff   = None\n",
    "my_mix    = None\n",
    "\n",
    "if my_sum is not None:\n",
    "    print('a + b matches:', simplify(sum_ab - my_sum) == sp.zeros(3,1))\n",
    "if my_diff is not None:\n",
    "    print('3a-2b matches:', simplify(diff_3a2b - my_diff) == sp.zeros(3,1))\n",
    "if my_mix is not None:\n",
    "    print('mix matches:  ', simplify(half_mix - my_mix) == sp.zeros(3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex1-norms",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Exercise 1(b)(c): Norms and normalization ---\n",
    "norm_a = sqrt(a.dot(a))\n",
    "norm_b = sqrt(b.dot(b))\n",
    "a_hat  = a / norm_a\n",
    "\n",
    "print(f'||a|| = {norm_a} = {float(norm_a):.6f}')\n",
    "print(f'||b|| = {norm_b} = {float(norm_b):.6f}')\n",
    "print(f'a_hat = {a_hat.T}')\n",
    "print(f'||a_hat|| = {simplify(sqrt(a_hat.dot(a_hat)))} (should be 1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex1-triangle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Exercise 1(d): Triangle inequality ---\n",
    "norm_sum = sqrt((a + b).dot(a + b))\n",
    "sum_norms = norm_a + norm_b\n",
    "\n",
    "print(f'||a + b||      = {simplify(norm_sum)} ≈ {float(norm_sum):.6f}')\n",
    "print(f'||a|| + ||b||  = {simplify(sum_norms)} ≈ {float(sum_norms):.6f}')\n",
    "print(f'Triangle inequality holds: {simplify(sum_norms - norm_sum) >= 0}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex2-lincombo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Exercise 2(b): Linear combination to express u = c1*v1 + c2*v2 ---\n",
    "# Solve the system [v1 | v2] * [c1; c2] = u\n",
    "\n",
    "v1 = sp.Matrix([1, 1])\n",
    "v2 = sp.Matrix([1, -1])\n",
    "u  = sp.Matrix([4, 2])\n",
    "\n",
    "# Stack v1, v2 as columns to form the coefficient matrix\n",
    "V = sp.Matrix([[1, 1],\n",
    "               [1, -1]])\n",
    "\n",
    "c = V.solve(u)  # Solve Vc = u\n",
    "c1, c2 = c\n",
    "\n",
    "print(f'c1 = {c1}, c2 = {c2}')\n",
    "print(f'Verification: c1*v1 + c2*v2 = {(c1*v1 + c2*v2).T} (should be {u.T})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sec2-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2 — Geometric Visualization\n",
    "\n",
    "We plot three things:\n",
    "1. **Vector addition** — the parallelogram rule in $\\mathbb{R}^2$\n",
    "2. **Scalar multiplication** — stretching, compressing, reversing\n",
    "3. **Normalization** — projecting onto the unit circle\n",
    "\n",
    "We work in $\\mathbb{R}^2$ for easy visualization, using $\\mathbf{a}_{2d} = (2, -3)^\\top$ (the first two components of $\\mathbf{a}$ from the exercises)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vector-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy versions for plotting (2D projections)\n",
    "a2 = np.array([2, -3])\n",
    "b2 = np.array([-1, 4])\n",
    "\n",
    "def draw_vector(ax, origin, vec, color, label, lw=2.0, alpha=1.0):\n",
    "    \"\"\"Draw a vector as an arrow from origin.\"\"\"\n",
    "    ax.annotate(\n",
    "        '', \n",
    "        xy=origin + vec, \n",
    "        xytext=origin,\n",
    "        arrowprops=dict(arrowstyle='->', color=color, lw=lw)\n",
    "    )\n",
    "    # Label at midpoint, slightly offset\n",
    "    mid = origin + vec * 0.55\n",
    "    ax.text(mid[0] + 0.1, mid[1] + 0.1, label, color=color, fontsize=12, fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallelogram-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot 1: Parallelogram rule for vector addition ---\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "origin = np.array([0, 0])\n",
    "\n",
    "# Draw a, b, a+b\n",
    "draw_vector(ax, origin, a2, TS_BLUE,  r'$\\mathbf{a}$')\n",
    "draw_vector(ax, origin, b2, TS_GREEN, r'$\\mathbf{b}$')\n",
    "draw_vector(ax, origin, a2 + b2, TS_RED, r'$\\mathbf{a}+\\mathbf{b}$', lw=2.5)\n",
    "\n",
    "# Draw dashed parallelogram sides\n",
    "draw_vector(ax, a2, b2, TS_GREEN, '', lw=1.0, alpha=0.5)\n",
    "draw_vector(ax, b2, a2, TS_BLUE,  '', lw=1.0, alpha=0.5)\n",
    "\n",
    "# Formatting\n",
    "lim = 6\n",
    "ax.set_xlim(-lim, lim)\n",
    "ax.set_ylim(-lim, lim)\n",
    "ax.axhline(0, color=TS_GRAY, lw=0.8)\n",
    "ax.axvline(0, color=TS_GRAY, lw=0.8)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlabel('$x_1$', fontsize=13)\n",
    "ax.set_ylabel('$x_2$', fontsize=13)\n",
    "ax.set_title('Vector Addition: The Parallelogram Rule', \n",
    "             fontweight='bold', color=TS_BLUE, fontsize=14)\n",
    "\n",
    "# Annotate the parallelogram\n",
    "ax.text(-3, -4.5, \n",
    "        r'The dashed lines complete the parallelogram.' + '\\n' +\n",
    "        r'$\\mathbf{a}+\\mathbf{b}$ is the diagonal.',\n",
    "        fontsize=10, color=TS_GRAY,\n",
    "        bbox=dict(boxstyle='round,pad=0.3', facecolor=TS_LIGHT, edgecolor=TS_GRAY))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../../assets/figures/m00-u01-parallelogram.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallelogram-analysis",
   "metadata": {},
   "source": [
    "### What Do You See?\n",
    "\n",
    "1. Does the visual result match your computed value of $\\mathbf{a} + \\mathbf{b}$ from Exercise 1(a)? Read the endpoint of the red arrow.\n",
    "2. Notice that $\\mathbf{a} + \\mathbf{b}$ can also be found by placing $\\mathbf{b}$ at the tip of $\\mathbf{a}$ (or vice versa). The parallelogram makes both paths visible simultaneously.\n",
    "\n",
    "**Analysis.** Vector addition is commutative — $\\mathbf{a} + \\mathbf{b} = \\mathbf{b} + \\mathbf{a}$ — and the parallelogram makes this geometric fact obvious: the diagonal is the same regardless of which side you traverse first. This commutativity holds in $\\mathbb{R}^n$ for any $n$, even though we can only plot in 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scalar-mult-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot 2: Scalar multiplication and normalization ---\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
    "\n",
    "# Left panel: scalar multiplication\n",
    "ax = axes[0]\n",
    "origin = np.array([0, 0])\n",
    "scalars = [2.0, 1.0, 0.5, -1.0, -1.5]\n",
    "colors  = [TS_RED, TS_BLUE, TS_GREEN, TS_AMBER, TS_GRAY]\n",
    "labels  = ['2a', 'a', '0.5a', '−a', '−1.5a']\n",
    "\n",
    "for c, col, lab in zip(scalars, colors, labels):\n",
    "    draw_vector(ax, origin, c * a2, col, f'${lab}$')\n",
    "\n",
    "lim = 6\n",
    "ax.set_xlim(-lim, lim)\n",
    "ax.set_ylim(-lim, lim)\n",
    "ax.axhline(0, color=TS_GRAY, lw=0.8)\n",
    "ax.axvline(0, color=TS_GRAY, lw=0.8)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlabel('$x_1$')\n",
    "ax.set_ylabel('$x_2$')\n",
    "ax.set_title('Scalar Multiplication', fontweight='bold', color=TS_BLUE)\n",
    "\n",
    "# Right panel: normalization (unit circle)\n",
    "ax2 = axes[1]\n",
    "theta_circle = np.linspace(0, 2*np.pi, 300)\n",
    "ax2.plot(np.cos(theta_circle), np.sin(theta_circle), \n",
    "         color=TS_GRAY, lw=1.2, linestyle='--', label='Unit circle')\n",
    "\n",
    "# Draw several vectors and their normalizations\n",
    "test_vecs = [a2, b2, np.array([3, 1]), np.array([-2, -2])]\n",
    "vec_colors = [TS_BLUE, TS_GREEN, TS_AMBER, TS_RED]\n",
    "vec_labels = [r'$\\mathbf{a}$', r'$\\mathbf{b}$', \n",
    "              r'$(3,1)$', r'$(-2,-2)$']\n",
    "\n",
    "for v, col, lab in zip(test_vecs, vec_colors, vec_labels):\n",
    "    v_hat = v / np.linalg.norm(v)\n",
    "    draw_vector(ax2, np.array([0,0]), v * 0.3, col, '', lw=1.0, alpha=0.4)\n",
    "    ax2.plot(*v_hat, 'o', color=col, markersize=8, label=f'{lab} → $\\\\hat{{v}}$')\n",
    "    draw_vector(ax2, np.array([0,0]), v_hat, col, '', lw=2.0)\n",
    "\n",
    "ax2.set_xlim(-1.8, 1.8)\n",
    "ax2.set_ylim(-1.8, 1.8)\n",
    "ax2.axhline(0, color=TS_GRAY, lw=0.8)\n",
    "ax2.axvline(0, color=TS_GRAY, lw=0.8)\n",
    "ax2.set_aspect('equal')\n",
    "ax2.set_xlabel('$x_1$')\n",
    "ax2.set_ylabel('$x_2$')\n",
    "ax2.set_title('Normalization: All Directions Land on the Unit Circle', \n",
    "              fontweight='bold', color=TS_BLUE)\n",
    "ax2.legend(loc='upper right', fontsize=9)\n",
    "\n",
    "plt.suptitle('Module 00, Unit 01: Scalar Multiplication & Normalization',\n",
    "             fontsize=13, fontweight='bold', color=TS_GRAY, y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../../assets/figures/m00-u01-scalar-normalization.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scalar-analysis",
   "metadata": {},
   "source": [
    "### What Do You See?\n",
    "\n",
    "1. **Left panel**: All scalar multiples of $\\mathbf{a}$ lie on the same line through the origin. Positive scalars point the same direction; negative scalars reverse it. A scalar of magnitude less than 1 shrinks the vector.\n",
    "\n",
    "2. **Right panel**: Normalization projects every vector onto the unit circle — it strips away magnitude and retains only direction. Four very different vectors (different magnitudes, different directions) produce four different points on the unit circle, one for each direction.\n",
    "\n",
    "**Analysis.** The right panel foreshadows a key idea from Module 03: the *gradient* of a function is a vector, and its *direction* (normalized gradient) tells us which way is uphill, while its *magnitude* (norm of gradient) tells us how steep. Separating these two pieces of information — direction and magnitude — is exactly what normalization does."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sec3-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 3 — Unit Balls: $\\ell_1$, $\\ell_2$, $\\ell_\\infty$\n",
    "\n",
    "This section visualizes the geometry from Exercise 4. The shape of the unit ball determines the geometry of regularization — and explains *why* Lasso produces sparse solutions while Ridge does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unit-balls",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot the three unit balls ---\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "t = np.linspace(0, 2*np.pi, 1000)\n",
    "\n",
    "configs = [\n",
    "    # (title, boundary_x, boundary_y, corner_points, color, label)\n",
    "    (\n",
    "        r'$\\ell_2$ Unit Ball  $\\|\\mathbf{x}\\|_2 \\leq 1$',\n",
    "        np.cos(t), np.sin(t),\n",
    "        [(1,0), (0,1), (-1,0), (0,-1)],\n",
    "        TS_BLUE,\n",
    "        'Circle (disk)'\n",
    "    ),\n",
    "    (\n",
    "        r'$\\ell_1$ Unit Ball  $\\|\\mathbf{x}\\|_1 \\leq 1$',\n",
    "        np.array([1, 0, -1, 0, 1]),\n",
    "        np.array([0, 1, 0, -1, 0]),\n",
    "        [(1,0), (0,1), (-1,0), (0,-1)],\n",
    "        TS_GREEN,\n",
    "        'Diamond (rotated square)'\n",
    "    ),\n",
    "    (\n",
    "        r'$\\ell_\\infty$ Unit Ball  $\\|\\mathbf{x}\\|_\\infty \\leq 1$',\n",
    "        np.array([1, 1, -1, -1, 1]),\n",
    "        np.array([1, -1, -1, 1, 1]),\n",
    "        [(1,0), (0,1), (-1,0), (0,-1)],\n",
    "        TS_AMBER,\n",
    "        'Axis-aligned square'\n",
    "    )\n",
    "]\n",
    "\n",
    "for ax, (title, bx, by, corners, color, shape_label) in zip(axes, configs):\n",
    "    ax.fill(bx, by, color=color, alpha=0.15)\n",
    "    ax.plot(bx, by, color=color, lw=2.5)\n",
    "    \n",
    "    # Mark axis intersections\n",
    "    for cx, cy in corners:\n",
    "        ax.plot(cx, cy, 'o', color=color, markersize=8, zorder=5)\n",
    "        ax.annotate(f'({cx},{cy})', (cx, cy), \n",
    "                    textcoords='offset points', xytext=(5,5),\n",
    "                    fontsize=9, color=color)\n",
    "    \n",
    "    ax.axhline(0, color=TS_GRAY, lw=0.8)\n",
    "    ax.axvline(0, color=TS_GRAY, lw=0.8)\n",
    "    ax.set_xlim(-1.6, 1.6)\n",
    "    ax.set_ylim(-1.6, 1.6)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xlabel('$\\\\beta_1$')\n",
    "    ax.set_ylabel('$\\\\beta_2$')\n",
    "    ax.set_title(title, fontweight='bold', color=color, fontsize=12)\n",
    "    ax.text(0, -1.45, shape_label, ha='center', fontsize=10, \n",
    "            color=TS_GRAY, style='italic')\n",
    "\n",
    "plt.suptitle('Unit Balls in $\\\\mathbb{R}^2$: The Geometry of Regularization',\n",
    "             fontsize=14, fontweight='bold', color=TS_GRAY, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../../assets/figures/m00-u01-unit-balls.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unit-balls-analysis",
   "metadata": {},
   "source": [
    "### What Do You See?\n",
    "\n",
    "1. All three unit balls share the same four axis intersections: $(\\pm 1, 0)$ and $(0, \\pm 1)$. They differ in what happens *between* those points — the $\\ell_1$ ball is \"pinched\" toward the axes, while the $\\ell_\\infty$ ball bulges.\n",
    "\n",
    "2. The $\\ell_1$ ball has **corners on the coordinate axes**. This is the geometric reason Lasso produces sparsity.\n",
    "\n",
    "**Analysis.** When you minimize a loss function subject to a norm constraint, the solution tends to land where the constraint boundary first touches the loss function's level sets. For the $\\ell_1$ ball, the corners are on the axes — so the first contact tends to happen at a corner, which corresponds to one component of $\\boldsymbol{\\beta}$ being exactly zero (sparsity). The $\\ell_2$ ball has no corners — it's smooth everywhere — so the first contact is unlikely to land on an axis, and Ridge solutions are typically dense (no exact zeros).\n",
    "\n",
    "This geometric argument is the intuition behind one of the most important practical differences between Lasso and Ridge. We will revisit it formally in Module 04 when we cover constrained optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sec4-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 4 — Statistical Bridge: The Ridge Penalty Surface\n",
    "\n",
    "Exercise 3 asked you to work with the Ridge penalty $\\|\\boldsymbol{\\beta}\\|^2$ at specific points. Here we plot the penalty as a **surface** over all of parameter space — your first look at what an optimization landscape looks like in 2D.\n",
    "\n",
    "This is a preview of Module 04. For now, focus on the shape and what it implies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ridge-surface",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Ridge penalty surface: f(beta1, beta2) = beta1^2 + beta2^2 ---\n",
    "b1 = np.linspace(-5, 5, 200)\n",
    "b2 = np.linspace(-5, 5, 200)\n",
    "B1, B2 = np.meshgrid(b1, b2)\n",
    "Penalty = B1**2 + B2**2   # ||beta||^2\n",
    "\n",
    "fig = plt.figure(figsize=(16, 6))\n",
    "\n",
    "# --- Left: 3D surface ---\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "surf = ax1.plot_surface(B1, B2, Penalty, cmap='Blues', alpha=0.85, \n",
    "                         linewidth=0, antialiased=True)\n",
    "fig.colorbar(surf, ax=ax1, shrink=0.5, label=r'$\\|\\boldsymbol{\\beta}\\|^2$')\n",
    "\n",
    "# Mark the specific point from Exercise 3\n",
    "beta_ex = np.array([3, -4])\n",
    "penalty_ex = np.sum(beta_ex**2)\n",
    "ax1.scatter([beta_ex[0]], [beta_ex[1]], [penalty_ex], \n",
    "            color=TS_RED, s=80, zorder=5, label=r'$(3,-4)$')\n",
    "\n",
    "ax1.set_xlabel(r'$\\beta_1$', fontsize=11)\n",
    "ax1.set_ylabel(r'$\\beta_2$', fontsize=11)\n",
    "ax1.set_zlabel(r'$\\|\\boldsymbol{\\beta}\\|^2$', fontsize=11)\n",
    "ax1.set_title('Ridge Penalty Surface\\n' + r'$\\|\\boldsymbol{\\beta}\\|^2 = \\beta_1^2 + \\beta_2^2$',\n",
    "              fontweight='bold', color=TS_BLUE)\n",
    "ax1.legend(fontsize=10)\n",
    "\n",
    "# --- Right: Contour plot (top-down view = level curves) ---\n",
    "ax2 = fig.add_subplot(122)\n",
    "levels = [1, 4, 9, 16, 25]\n",
    "cs = ax2.contour(B1, B2, Penalty, levels=levels, colors=[TS_BLUE]*len(levels), linewidths=1.5)\n",
    "ax2.clabel(cs, fmt=r'$\\|\\beta\\|^2 = %g$', fontsize=9)\n",
    "ax2.contourf(B1, B2, Penalty, levels=20, cmap='Blues', alpha=0.3)\n",
    "\n",
    "# Mark the two points from Exercise 3(d): both have ||beta||^2 = 25\n",
    "ax2.plot(5, 0, 's', color=TS_GREEN, markersize=10, label=r'$\\boldsymbol{\\beta}^{(1)} = (5,0)$')\n",
    "ax2.plot(3, 4, 's', color=TS_AMBER, markersize=10, label=r'$\\boldsymbol{\\beta}^{(2)} = (3,4)$')\n",
    "ax2.plot(3, -4, 'o', color=TS_RED, markersize=10, label=r'$(3,-4)$ from Ex. 3')\n",
    "\n",
    "ax2.axhline(0, color=TS_GRAY, lw=0.8)\n",
    "ax2.axvline(0, color=TS_GRAY, lw=0.8)\n",
    "ax2.set_aspect('equal')\n",
    "ax2.set_xlabel(r'$\\beta_1$', fontsize=12)\n",
    "ax2.set_ylabel(r'$\\beta_2$', fontsize=12)\n",
    "ax2.set_title('Level Curves of the Ridge Penalty\\n(Top-Down View)',\n",
    "              fontweight='bold', color=TS_BLUE)\n",
    "ax2.legend(loc='upper right', fontsize=9)\n",
    "\n",
    "plt.suptitle('Module 00, Unit 01 — Statistical Bridge: Ridge Penalty',\n",
    "             fontsize=13, fontweight='bold', color=TS_GRAY)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../../assets/figures/m00-u01-ridge-surface.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'Penalty at (3,-4): {penalty_ex}')\n",
    "print(f'Penalty at (5, 0): {5**2 + 0**2}')\n",
    "print(f'Penalty at (3, 4): {3**2 + 4**2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ridge-analysis",
   "metadata": {},
   "source": [
    "### What Do You See?\n",
    "\n",
    "1. The Ridge penalty surface is a **paraboloid** — a bowl-shaped surface with its minimum at the origin $\\boldsymbol{\\beta} = \\mathbf{0}$. Every point on the surface represents the penalty cost of choosing a particular parameter vector.\n",
    "\n",
    "2. The level curves (right panel) are **circles** centered at the origin. Two very different parameter vectors — $(5,0)$ and $(3,4)$ — lie on the same level curve because $\\|(5,0)\\|^2 = \\|(3,4)\\|^2 = 25$. The Ridge penalty cannot distinguish between them.\n",
    "\n",
    "**Analysis.** This confirms your answer to Exercise 3(d): Ridge regularization penalizes the *magnitude* of $\\boldsymbol{\\beta}$ equally in all directions. It has no preference for solutions on the axes vs. solutions spread across components. This is a geometric property of the $\\ell_2$ norm, visible in the circular level curves.\n",
    "\n",
    "In Module 04, when we study optimization, we will add the *loss function* to this picture and find the parameter vector that minimizes their sum. The level curves you see here are the constraint geometry; the loss function provides the other half of the picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lambda-effect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Bonus: Effect of lambda on the regularization constraint ---\n",
    "# For a given budget B, the constraint ||beta||^2 <= B defines a disk of radius sqrt(B).\n",
    "# Larger lambda => smaller allowed region.\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "theta_circ = np.linspace(0, 2*np.pi, 300)\n",
    "\n",
    "budgets = [0.5, 2, 5, 12]\n",
    "lambda_labels = ['Large λ\\n(tight constraint)', 'Medium λ', \n",
    "                 'Small λ', 'Very small λ\\n(loose constraint)']\n",
    "colors = [TS_RED, TS_AMBER, TS_GREEN, TS_BLUE]\n",
    "alphas = [0.9, 0.7, 0.5, 0.3]\n",
    "\n",
    "for B, lab, col, alp in zip(budgets, lambda_labels, colors, alphas):\n",
    "    r = np.sqrt(B)\n",
    "    ax.plot(r*np.cos(theta_circ), r*np.sin(theta_circ), \n",
    "            color=col, lw=2, alpha=alp, label=f'Budget $B={B}$, $r={r:.2f}$: {lab}')\n",
    "\n",
    "ax.axhline(0, color=TS_GRAY, lw=0.8)\n",
    "ax.axvline(0, color=TS_GRAY, lw=0.8)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(-4, 4)\n",
    "ax.set_ylim(-4, 4)\n",
    "ax.set_xlabel(r'$\\beta_1$', fontsize=13)\n",
    "ax.set_ylabel(r'$\\beta_2$', fontsize=13)\n",
    "ax.set_title(r'Ridge Constraint Regions $\\|\\boldsymbol{\\beta}\\|^2 \\leq B$' + '\\n' +\n",
    "             'Larger $\\\\lambda$ ⟹ Smaller Allowed Region ⟹ $\\\\boldsymbol{\\\\beta}$ closer to origin',\n",
    "             fontweight='bold', color=TS_BLUE)\n",
    "ax.legend(loc='upper right', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../../assets/figures/m00-u01-lambda-effect.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lambda-analysis",
   "metadata": {},
   "source": [
    "This plot answers Exercise 3(c) geometrically: as $\\lambda \\to \\infty$, the allowed region for $\\boldsymbol{\\beta}$ shrinks to a single point — the origin. The regularization forces $\\boldsymbol{\\beta} \\to \\mathbf{0}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extension-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Extension Challenge (Optional)\n",
    "\n",
    "**Challenge.** Extend the unit ball visualization to the $\\ell_p$ norm for values of $p$ between 1 and $\\infty$. The $\\ell_p$ norm is defined as:\n",
    "\n",
    "$$\\|\\mathbf{x}\\|_p = \\left(|x_1|^p + |x_2|^p\\right)^{1/p}$$\n",
    "\n",
    "Plot the unit ball boundary $\\|\\mathbf{x}\\|_p = 1$ for $p \\in \\{1, 1.2, 1.5, 2, 3, 5, 10, \\infty\\}$ on the same axes and animate or overlay them. How does the shape transition from the $\\ell_1$ diamond to the $\\ell_2$ circle to the $\\ell_\\infty$ square? Where do the corners appear and disappear?\n",
    "\n",
    "*Hint*: For a given $p$, parameterize the boundary by $x_1 = \\text{sign}(\\cos\\theta)|\\cos\\theta|^{2/p}$ and $x_2 = \\text{sign}(\\sin\\theta)|\\sin\\theta|^{2/p}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extension-workspace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extension challenge workspace\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lab Summary\n",
    "\n",
    "| What we did | Key result |\n",
    "|---|---|\n",
    "| Verified Exercise 1–2 symbolically | Hand computations confirmed with exact arithmetic |\n",
    "| Visualized vector addition | Parallelogram rule — geometric and algebraic views are equivalent |\n",
    "| Visualized normalization | All directions project to the unit circle; magnitude is stripped |\n",
    "| Plotted $\\ell_1$, $\\ell_2$, $\\ell_\\infty$ unit balls | $\\ell_1$ corners explain Lasso sparsity; $\\ell_2$ smoothness explains Ridge density |\n",
    "| Plotted Ridge penalty surface + level curves | Level curves are circles; $(5,0)$ and $(3,4)$ are indistinguishable to Ridge |\n",
    "| Plotted $\\lambda$ effect on constraint region | $\\lambda \\to \\infty$ collapses allowed region to the origin |\n",
    "\n",
    "## Reflection\n",
    "\n",
    "Before closing, answer briefly:\n",
    "\n",
    "1. **What did the Ridge surface visualization add that Exercise 3 alone could not?**  \n",
    "   *Your answer here*\n",
    "\n",
    "2. **The unit ball visualization shows that $\\ell_1$ and $\\ell_2$ balls share the same axis intercepts. Does this mean they impose the same constraint at those specific points? Why or why not?**  \n",
    "   *Your answer here*\n",
    "\n",
    "3. **What is one thing from this lab you want to revisit when we reach Module 04 on optimization?**  \n",
    "   *Your answer here*\n",
    "\n",
    "---\n",
    "\n",
    "**Next sub-unit**: Module 00, Unit 02 — Dot Products & Cross Products  \n",
    "**Solutions for this unit's exercises**: `threat-surfaces-solutions` repository, `module-00-orientation/unit-01-vectors-and-vector-spaces/`\n",
    "\n",
    "---\n",
    "*Python Lab | Module 00, Unit 01 — Threat Surfaces, fischer³ Education*"
   ]
  }
 ]
}"
